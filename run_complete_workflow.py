#!/usr/bin/env python3
"""
å®Œæ•´çš„æ•°æ®æ¸…æ´—å’Œè®­ç»ƒæµç¨‹
è‡ªåŠ¨æ‰§è¡Œï¼šbaselineè®­ç»ƒ -> æ•°æ®æ¸…æ´— -> æ¸…æ´—åè®­ç»ƒ -> æ€§èƒ½å¯¹æ¯”

Usage:
    python run_complete_workflow.py
"""

import subprocess
import sys
import time
from pathlib import Path
import json

# é…ç½®
EPOCHS = 30  # è®­ç»ƒè½®æ•°
BATCH_SIZE = 16  # ä½¿ç”¨ä¼˜åŒ–åçš„batch size
BASELINE_NAME = "yolov8n_baseline_fast2"  # ä½¿ç”¨ä½ åˆšè®­ç»ƒçš„baselineæ¨¡å‹
CLEANED_NAME = "yolov8n_cleaned_fast"  # æ¸…æ´—åçš„æ¨¡å‹åç§°
BASELINE_MODEL = f"runs/detect/{BASELINE_NAME}/weights/best.pt"

def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)

def wait_for_training_complete(model_path, max_wait=3600):
    """ç­‰å¾…è®­ç»ƒå®Œæˆ"""
    print(f"\nâ³ ç­‰å¾…è®­ç»ƒå®Œæˆ: {model_path}")
    start_time = time.time()
    
    while time.time() - start_time < max_wait:
        if Path(model_path).exists():
            print("âœ… è®­ç»ƒå®Œæˆï¼")
            return True
        time.sleep(10)
        print(".", end="", flush=True)
    
    print(f"\nâš ï¸  è¶…æ—¶ï¼šè®­ç»ƒå¯èƒ½ä»åœ¨è¿›è¡Œä¸­")
    return False

def step1_train_baseline():
    """æ­¥éª¤1: è®­ç»ƒbaselineæ¨¡å‹"""
    print_section("æ­¥éª¤1: è®­ç»ƒBaselineæ¨¡å‹")
    
    print(f"é…ç½®:")
    print(f"  Epochs: {EPOCHS}")
    print(f"  Batch size: {BATCH_SIZE}")
    print(f"  æ•°æ®é›†: dataset.yaml (åŸå§‹è®­ç»ƒé›†)")
    print(f"  è¾“å‡º: {BASELINE_NAME}")
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if Path(BASELINE_MODEL).exists():
        print(f"\nâœ… Baselineæ¨¡å‹å·²å­˜åœ¨: {BASELINE_MODEL}")
        print("   è‡ªåŠ¨è·³è¿‡baselineè®­ç»ƒï¼Œä½¿ç”¨å·²æœ‰æ¨¡å‹")
        return True
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒbaselineæ¨¡å‹...")
    cmd = [
        sys.executable,
        "train_standard.py",
        "--data", "dataset.yaml",
        "--epochs", str(EPOCHS),
        "--batch", str(BATCH_SIZE),
        "--imgsz", "640",
        "--device", "0",
        "--workers", "4",  # ä½¿ç”¨ä¼˜åŒ–åçš„workers
        "--name", BASELINE_NAME
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print("âŒ Baselineè®­ç»ƒå¤±è´¥")
        return False
    
    if Path(BASELINE_MODEL).exists():
        print(f"âœ… Baselineè®­ç»ƒå®Œæˆ: {BASELINE_MODEL}")
        return True
    else:
        print("âŒ è®­ç»ƒå®Œæˆä½†æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
        return False

def step2_analyze_quality():
    """æ­¥éª¤2: åˆ†æè®­ç»ƒé›†æ ‡ç­¾è´¨é‡"""
    print_section("æ­¥éª¤2: åˆ†æè®­ç»ƒé›†æ ‡ç­¾è´¨é‡")
    
    if not Path(BASELINE_MODEL).exists():
        print(f"âŒ æ‰¾ä¸åˆ°baselineæ¨¡å‹: {BASELINE_MODEL}")
        return False
    
    print(f"ä½¿ç”¨baselineæ¨¡å‹: {BASELINE_MODEL}")
    print(f"åˆ†ææ•°æ®é›†: train (è®­ç»ƒé›†)")
    
    cmd = [
        sys.executable,
        "tools/run_label_quality_analysis.py",
        "--model", BASELINE_MODEL,
        "--split", "train"
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print("âŒ æ ‡ç­¾è´¨é‡åˆ†æå¤±è´¥")
        return False
    
    quality_report = "quality_report_train.json"
    if Path(quality_report).exists():
        print(f"âœ… è´¨é‡åˆ†æå®Œæˆ: {quality_report}")
        return True
    else:
        print("âŒ åˆ†æå®Œæˆä½†æ‰¾ä¸åˆ°æŠ¥å‘Šæ–‡ä»¶")
        return False

def step3_clean_dataset():
    """æ­¥éª¤3: æ¸…æ´—è®­ç»ƒé›†"""
    print_section("æ­¥éª¤3: æ¸…æ´—è®­ç»ƒé›†æ ‡æ³¨")
    
    quality_report = "quality_report_train.json"
    predictions_file = "predictions_train_coco.json"
    
    if not Path(quality_report).exists():
        print(f"âŒ æ‰¾ä¸åˆ°è´¨é‡æŠ¥å‘Š: {quality_report}")
        print("   è¯·å…ˆè¿è¡Œæ­¥éª¤2")
        return False
    
    if not Path(predictions_file).exists():
        print(f"âŒ æ‰¾ä¸åˆ°é¢„æµ‹æ–‡ä»¶: {predictions_file}")
        print("   è¯·å…ˆè¿è¡Œæ­¥éª¤2")
        return False
    
    print(f"ä½¿ç”¨è´¨é‡æŠ¥å‘Š: {quality_report}")
    print(f"ä½¿ç”¨é¢„æµ‹æ–‡ä»¶: {predictions_file}")
    
    cmd = [
        sys.executable,
        "tools/clean_dataset.py",
        "--quality-report", quality_report,
        "--predictions", predictions_file,
        "--output", "cleaned_train_annotations.json"
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print("âŒ æ•°æ®æ¸…æ´—å¤±è´¥")
        return False
    
    cleaned_file = "cleaned_train_annotations.json"
    if Path(cleaned_file).exists():
        print(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {cleaned_file}")
        return True
    else:
        print("âŒ æ¸…æ´—å®Œæˆä½†æ‰¾ä¸åˆ°è¾“å‡ºæ–‡ä»¶")
        return False

def step4_convert_and_prepare():
    """æ­¥éª¤4: è½¬æ¢æ ¼å¼å¹¶å‡†å¤‡æ¸…æ´—åçš„æ•°æ®é›†"""
    print_section("æ­¥éª¤4: å‡†å¤‡æ¸…æ´—åçš„æ•°æ®é›†")
    
    # ä½¿ç”¨run_cleaning_and_comparison.pyçš„æ­¥éª¤2-4
    print("æ‰§è¡Œæ ¼å¼è½¬æ¢å’Œæ–‡ä»¶å‡†å¤‡...")
    
    # è¿™é‡Œå¯ä»¥è°ƒç”¨run_cleaning_and_comparison.pyçš„ç›¸å…³å‡½æ•°
    # æˆ–è€…ç›´æ¥æ‰§è¡Œå‘½ä»¤
    try:
        from tools.run_cleaning_and_comparison import (
            step2_convert_to_yolo,
            step3_copy_images,
            step4_create_dataset_yaml
        )
        
        # æ­¥éª¤2: è½¬æ¢ä¸ºYOLOæ ¼å¼
        print("\n[4.1] è½¬æ¢ä¸ºYOLOæ ¼å¼...")
        labels_dir = step2_convert_to_yolo()
        if not labels_dir:
            return False
        
        # æ­¥éª¤3: å¤åˆ¶å›¾ç‰‡
        print("\n[4.2] å¤åˆ¶å›¾ç‰‡æ–‡ä»¶...")
        if not step3_copy_images():
            return False
        
        # æ­¥éª¤4: åˆ›å»ºæ•°æ®é›†é…ç½®
        print("\n[4.3] åˆ›å»ºæ•°æ®é›†é…ç½®...")
        yaml_file = step4_create_dataset_yaml()
        if not yaml_file:
            return False
        
        print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ: {yaml_file}")
        return True
        
    except Exception as e:
        print(f"âŒ å‡†å¤‡æ•°æ®é›†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def step5_train_cleaned():
    """æ­¥éª¤5: ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®è®­ç»ƒ"""
    print_section("æ­¥éª¤5: ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®è®­ç»ƒ")
    
    dataset_yaml = "dataset_cleaned.yaml"
    if not Path(dataset_yaml).exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®é›†é…ç½®: {dataset_yaml}")
        print("   è¯·å…ˆè¿è¡Œæ­¥éª¤4")
        return False
    
    print(f"é…ç½®:")
    print(f"  Epochs: {EPOCHS}")
    print(f"  Batch size: {BATCH_SIZE}")
    print(f"  æ•°æ®é›†: {dataset_yaml} (æ¸…æ´—åçš„è®­ç»ƒé›†)")
    print(f"  è¾“å‡º: {CLEANED_NAME}")
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ¸…æ´—åçš„æ¨¡å‹...")
    cmd = [
        sys.executable,
        "train_standard.py",
        "--data", dataset_yaml,
        "--epochs", str(EPOCHS),
        "--batch", str(BATCH_SIZE),
        "--imgsz", "640",
        "--device", "0",
        "--workers", "4",  # ä½¿ç”¨ä¼˜åŒ–åçš„workers
        "--name", CLEANED_NAME
    ]
    
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print("âŒ æ¸…æ´—åè®­ç»ƒå¤±è´¥")
        return False
    
    cleaned_model = f"runs/detect/{CLEANED_NAME}/weights/best.pt"
    if Path(cleaned_model).exists():
        print(f"âœ… æ¸…æ´—åè®­ç»ƒå®Œæˆ: {cleaned_model}")
        return True
    else:
        print("âŒ è®­ç»ƒå®Œæˆä½†æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶")
        return False

def step6_compare_performance():
    """æ­¥éª¤6: å¯¹æ¯”æ€§èƒ½"""
    print_section("æ­¥éª¤6: æ€§èƒ½å¯¹æ¯”")
    
    baseline_model = BASELINE_MODEL
    cleaned_model = f"runs/detect/{CLEANED_NAME}/weights/best.pt"
    
    # è¯»å–baselineç»“æœ
    baseline_results = Path(baseline_model).parent.parent / "results.csv"
    cleaned_results = Path(cleaned_model).parent.parent / "results.csv"
    
    baseline_map = None
    cleaned_map = None
    
    # è¯»å–baseline mAP
    if baseline_results.exists():
        try:
            import pandas as pd
            df = pd.read_csv(baseline_results)
            if len(df) > 0:
                last_row = df.iloc[-1]
                for col in df.columns:
                    if 'map50' in col.lower() and 'metrics' in col.lower():
                        baseline_map = last_row.get(col, None)
                        break
        except:
            pass
    
    # è¯»å–cleaned mAP
    if cleaned_results.exists():
        try:
            import pandas as pd
            df = pd.read_csv(cleaned_results)
            if len(df) > 0:
                last_row = df.iloc[-1]
                for col in df.columns:
                    if 'map50' in col.lower() and 'metrics' in col.lower():
                        cleaned_map = last_row.get(col, None)
                        break
        except:
            pass
    
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
    print(f"  Baselineæ¨¡å‹: {baseline_model}")
    if baseline_map:
        print(f"    mAP@0.5: {baseline_map:.4f} ({baseline_map*100:.2f}%)")
    else:
        print(f"    mAP@0.5: æ— æ³•è¯»å–")
    
    print(f"\n  æ¸…æ´—åæ¨¡å‹: {cleaned_model}")
    if cleaned_map:
        print(f"    mAP@0.5: {cleaned_map:.4f} ({cleaned_map*100:.2f}%)")
    else:
        print(f"    mAP@0.5: æ— æ³•è¯»å–")
    
    if baseline_map and cleaned_map:
        improvement = cleaned_map - baseline_map
        improvement_pct = (improvement / baseline_map * 100) if baseline_map > 0 else 0
        print(f"\n  âœ… æ€§èƒ½æå‡:")
        print(f"    ç»å¯¹æå‡: {improvement:+.4f} ({improvement*100:+.2f}%)")
        print(f"    ç›¸å¯¹æå‡: {improvement_pct:+.2f}%")
        
        # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "baseline": {
                "model": str(baseline_model),
                "mAP50": float(baseline_map)
            },
            "cleaned": {
                "model": str(cleaned_model),
                "mAP50": float(cleaned_map)
            },
            "improvement": {
                "absolute": float(improvement),
                "percentage": float(improvement_pct)
            }
        }
        
        report_file = "complete_workflow_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return True

def main():
    """ä¸»æµç¨‹"""
    print("=" * 70)
    print("å®Œæ•´çš„æ•°æ®æ¸…æ´—å’Œè®­ç»ƒæµç¨‹")
    print("=" * 70)
    print(f"\né…ç½®:")
    print(f"  Epochs: {EPOCHS}")
    print(f"  Batch size: {BATCH_SIZE}")
    print(f"  Baselineåç§°: {BASELINE_NAME}")
    print(f"  æ¸…æ´—ååç§°: {CLEANED_NAME}")
    
    steps = [
        ("è®­ç»ƒBaseline", step1_train_baseline),
        ("åˆ†ææ ‡ç­¾è´¨é‡", step2_analyze_quality),
        ("æ¸…æ´—æ•°æ®é›†", step3_clean_dataset),
        ("å‡†å¤‡æ¸…æ´—åçš„æ•°æ®é›†", step4_convert_and_prepare),
        ("è®­ç»ƒæ¸…æ´—åçš„æ¨¡å‹", step5_train_cleaned),
        ("æ€§èƒ½å¯¹æ¯”", step6_compare_performance),
    ]
    
    for i, (name, func) in enumerate(steps, 1):
        print(f"\n{'='*70}")
        print(f"æ‰§è¡Œæ­¥éª¤ {i}/{len(steps)}: {name}")
        print(f"{'='*70}")
        
        if not func():
            print(f"\nâŒ æ­¥éª¤ {i} å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
            return False
        
        print(f"\nâœ… æ­¥éª¤ {i} å®Œæˆ")
    
    print("\n" + "=" * 70)
    print("âœ… å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
    print("=" * 70)
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

