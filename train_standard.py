#!/usr/bin/env python3
"""
æ ‡å‡†è®­ç»ƒè„šæœ¬ - ä¸ä¾èµ–3LC
ä½¿ç”¨æ ‡å‡†Ultralytics YOLOè¿›è¡Œè®­ç»ƒ

Usage:
    python train_standard.py
    python train_standard.py --data dataset.yaml --epochs 30 --batch 16
"""

import torch
from ultralytics import YOLO
import argparse
from pathlib import Path
import gc

# ============================================================================
# CONFIGURATION - é»˜è®¤é…ç½®ï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ï¼‰
# ============================================================================

# æ•°æ®é›†é…ç½®
DATASET_YAML = "dataset.yaml"  # é»˜è®¤ä½¿ç”¨åŸå§‹æ•°æ®é›†
# DATASET_YAML = "dataset_cleaned.yaml"  # ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®é›†

# è®­ç»ƒè¶…å‚æ•°
EPOCHS = 30  # è®­ç»ƒè½®æ•°
BATCH_SIZE = 16  # æ‰¹æ¬¡å¤§å°
IMAGE_SIZE = 640  # è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆç«èµ›è¦æ±‚å›ºå®šï¼‰
DEVICE = 0  # GPUè®¾å¤‡ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€å—GPUï¼Œ'cpu'è¡¨ç¤ºCPUï¼‰
WORKERS = 4  # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°

# é«˜çº§è¶…å‚æ•°
LR0 = 0.01  # åˆå§‹å­¦ä¹ ç‡
PATIENCE = 20  # æ—©åœè€å¿ƒå€¼ï¼ˆæ— æ”¹è¿›çš„è½®æ•°ï¼‰

# æ•°æ®å¢å¼º
USE_AUGMENTATION = False  # æ˜¯å¦å¯ç”¨å¢å¼ºï¼ˆmosaic, mixupç­‰ï¼‰

# æ¨¡å‹é…ç½®
MODEL_WEIGHTS = "yolov8n.pt"  # é¢„è®­ç»ƒæƒé‡
PROJECT_NAME = "runs/detect"  # é¡¹ç›®ç›®å½•
RUN_NAME = "yolov8n_standard"  # è¿è¡Œåç§°

# ============================================================================
# è®­ç»ƒå‡½æ•°
# ============================================================================

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    parser = argparse.ArgumentParser(description="æ ‡å‡†YOLOv8è®­ç»ƒè„šæœ¬")
    parser.add_argument("--data", type=str, default=DATASET_YAML, help="æ•°æ®é›†YAMLæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--epochs", type=int, default=EPOCHS, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch", type=int, default=BATCH_SIZE, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--imgsz", type=int, default=IMAGE_SIZE, help="å›¾åƒå°ºå¯¸")
    parser.add_argument("--device", default=DEVICE, help="è®¾å¤‡ï¼ˆGPUç¼–å·æˆ–'cpu'ï¼‰")
    parser.add_argument("--workers", type=int, default=WORKERS, help="æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°")
    parser.add_argument("--lr0", type=float, default=LR0, help="åˆå§‹å­¦ä¹ ç‡")
    parser.add_argument("--patience", type=int, default=PATIENCE, help="æ—©åœè€å¿ƒå€¼")
    parser.add_argument("--augment", action="store_true", help="å¯ç”¨æ•°æ®å¢å¼º")
    parser.add_argument("--model", type=str, default=MODEL_WEIGHTS, help="é¢„è®­ç»ƒæ¨¡å‹æƒé‡")
    parser.add_argument("--name", type=str, default=RUN_NAME, help="è¿è¡Œåç§°")
    parser.add_argument("--project", type=str, default=PROJECT_NAME, help="é¡¹ç›®ç›®å½•")
    parser.add_argument("--resume", type=str, default=None, help="æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„")
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("COTTON WEED DETECTION - æ ‡å‡†è®­ç»ƒï¼ˆä¸ä¾èµ–3LCï¼‰")
    print("=" * 70)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("\nç¯å¢ƒä¿¡æ¯:")
    print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"  CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"  GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
    dataset_path = Path(args.data)
    if not dataset_path.exists():
        print(f"\nâŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†é…ç½®æ–‡ä»¶: {args.data}")
        print(f"   å½“å‰ç›®å½•: {Path.cwd()}")
        print(f"   è¯·ç¡®ä¿æ•°æ®é›†YAMLæ–‡ä»¶å­˜åœ¨")
        return
    
    print(f"\nâœ… æ•°æ®é›†é…ç½®: {args.data}")
    
    # æ˜¾ç¤ºè®­ç»ƒé…ç½®
    print("\n" + "=" * 70)
    print("è®­ç»ƒé…ç½®")
    print("=" * 70)
    print(f"  è¿è¡Œåç§°: {args.name}")
    print(f"  è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch}")
    print(f"  å›¾åƒå°ºå¯¸: {args.imgsz}")
    print(f"  è®¾å¤‡: {'GPU ' + str(args.device) if args.device != 'cpu' else 'CPU'}")
    print(f"  å­¦ä¹ ç‡: {args.lr0}")
    print(f"  æ—©åœè€å¿ƒå€¼: {args.patience}")
    print(f"  æ•°æ®å¢å¼º: {'å¯ç”¨' if args.augment else 'ç¦ç”¨'}")
    
    # åŠ è½½æ¨¡å‹
    print("\n" + "=" * 70)
    print("åŠ è½½æ¨¡å‹")
    print("=" * 70)
    # åŠ è½½æ¨¡å‹ï¼ˆæ”¯æŒæ¢å¤è®­ç»ƒï¼‰
    if args.resume:
        print(f"\næ¢å¤è®­ç»ƒ: {args.resume}")
        model = YOLO(args.resume)
        print(f"âœ… ä»checkpointæ¢å¤è®­ç»ƒ")
    else:
        print(f"\nåŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {args.model}")
        model = YOLO(args.model)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (YOLOv8n, ~3Må‚æ•°)")
    
    # å‡†å¤‡è®­ç»ƒå‚æ•°
    # å¼ºåˆ¶å•è¿›ç¨‹æ¨¡å¼ä»¥é¿å…å†…å­˜é—®é¢˜
    workers = 0 if args.workers == 0 else args.workers
    
    train_args = {
        "data": str(args.data),
        "epochs": args.epochs,
        "imgsz": args.imgsz,
        "batch": args.batch,
        "device": args.device,
        "workers": workers,  # ç¡®ä¿å•è¿›ç¨‹æ¨¡å¼
        "lr0": args.lr0,
        "patience": args.patience,
        "project": args.project,
        "name": args.name,
        "val": True,  # å¯ç”¨éªŒè¯
        "save": True,  # ä¿å­˜æ£€æŸ¥ç‚¹
        "plots": True,  # ç”Ÿæˆè®­ç»ƒå›¾è¡¨
        "verbose": True,  # æ˜¾ç¤ºè¯¦ç»†è®­ç»ƒè¿›åº¦
    }
    
    # å¦‚æœworkers=0ï¼Œç¦ç”¨å¤šè¿›ç¨‹ç›¸å…³çš„å¢å¼ºä»¥é¿å…å†…å­˜é—®é¢˜
    if workers == 0:
        print(f"\nâš ï¸  ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼ (workers=0) ä»¥é¿å…å†…å­˜é—®é¢˜")
        # ç¦ç”¨å¯èƒ½å ç”¨é¢å¤–å†…å­˜çš„å¢å¼º
        train_args["mosaic"] = 0.0  # ç¦ç”¨mosaicä»¥å‡å°‘å†…å­˜å ç”¨
    
    # å¦‚æœæä¾›äº†resumeå‚æ•°ï¼Œæ·»åŠ resumeæ ‡å¿—
    if args.resume:
        train_args["resume"] = True
    
    # æ·»åŠ æ•°æ®å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if args.augment:
        train_args.update({
            "mosaic": 1.0,  # Mosaicå¢å¼º
            "mixup": 0.05,  # Mixupå¢å¼º
            "copy_paste": 0.1,  # Copy-pasteå¢å¼º
        })
        print("\nâœ… æ•°æ®å¢å¼ºå·²å¯ç”¨")
    
    # æ¸…ç†å†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    gc.collect()
    
    # å¼€å§‹è®­ç»ƒ
    print("\n" + "=" * 70)
    print("å¼€å§‹è®­ç»ƒ")
    print("=" * 70 + "\n")
    
    try:
        results = model.train(**train_args)
        
        # è®­ç»ƒå®Œæˆ
        print("\n" + "=" * 70)
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print("=" * 70)
        print(f"\næ¨¡å‹æƒé‡ä¿å­˜ä½ç½®:")
        print(f"  æœ€ä½³æ¨¡å‹: {args.project}/{args.name}/weights/best.pt")
        print(f"  æœ€åæ¨¡å‹: {args.project}/{args.name}/weights/last.pt")
        
        if hasattr(results, 'results_dict'):
            print(f"\nè®­ç»ƒç»“æœ:")
            if 'metrics/mAP50' in results.results_dict:
                print(f"  mAP@0.5: {results.results_dict['metrics/mAP50']:.4f}")
            if 'metrics/mAP50-95' in results.results_dict:
                print(f"  mAP@0.5:0.95: {results.results_dict['metrics/mAP50-95']:.4f}")
        
        print(f"\nä¸‹ä¸€æ­¥:")
        print(f"  1. æŸ¥çœ‹è®­ç»ƒç»“æœ: {args.project}/{args.name}/")
        print(f"  2. ç”Ÿæˆé¢„æµ‹: python predict.py --model {args.project}/{args.name}/weights/best.pt")
        print(f"  3. æäº¤åˆ°Kaggle: ä¸Šä¼  submission.csv")
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
        # å¦‚æœæ˜¯å†…å­˜é”™è¯¯ï¼Œæä¾›è§£å†³å»ºè®®
        error_str = str(e).lower()
        if "memory" in error_str or "insufficient" in error_str or "allocate" in error_str:
            print("\n" + "=" * 70)
            print("ğŸ’¡ å†…å­˜ä¸è¶³è§£å†³æ–¹æ¡ˆ")
            print("=" * 70)
            print("1. å‡å°batch sizeï¼ˆå½“å‰: {}ï¼‰: --batch 4 æˆ– --batch 2".format(args.batch))
            print("2. ç¡®ä¿ä½¿ç”¨å•è¿›ç¨‹: --workers 0ï¼ˆå·²è®¾ç½®ï¼‰")
            print("3. å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº")
            print("4. å¢åŠ Windowsé¡µé¢æ–‡ä»¶å¤§å°:")
            print("   æ§åˆ¶é¢æ¿ > ç³»ç»Ÿ > é«˜çº§ç³»ç»Ÿè®¾ç½® > æ€§èƒ½è®¾ç½® > é«˜çº§ > è™šæ‹Ÿå†…å­˜")
            print("   å»ºè®®è®¾ç½®ä¸º: åˆå§‹å¤§å° 8192MB, æœ€å¤§å¤§å° 16384MB")
            print("5. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•ä½¿ç”¨CPUè®­ç»ƒ: --device cpu")
            print("\né‡æ–°è®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
            print(f"python train_standard.py --data {args.data} --epochs {args.epochs} --batch 4 --imgsz {args.imgsz} --device {args.device} --workers 0 --name {args.name} --resume {args.resume if args.resume else ''}")
        
        raise


if __name__ == "__main__":
    main()

